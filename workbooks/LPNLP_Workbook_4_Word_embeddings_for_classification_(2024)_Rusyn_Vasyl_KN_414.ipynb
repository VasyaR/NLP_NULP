{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "6bLSgXhBp_ik",
        "0qdP0X3Op_il",
        "0HMdK4nwp_in",
        "Q_5QUDc8p_io",
        "JWyNFYd7p_iq",
        "bnj-EyYPp_ir",
        "TDcdMxXLp_iu",
        "xORrcb8ap_iv",
        "XzQ3Q5Trp_iv",
        "oZGXRCNrlBde"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiiDM1V8p_iX"
      },
      "source": [
        "# Workbook 04: Word embeddings for text classification\n",
        "\n",
        "–£ —Ü—ñ–π —Ä–æ–±–æ—Ç—ñ –º–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ word embeddings –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç—ñ–≤.\n",
        "\n",
        "–ú–∞—î–º–æ –ø–æ–±–∞—á–∏—Ç–∏, —è–∫ word embeddings –æ—Å–æ–±–ª–∏–≤–æ —Å–∏–ª—å–Ω–æ –¥–æ–ø–æ–º–æ–≥–∞—é—Ç—å, –∫–æ–ª–∏ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ–±–∞–≥–∞—Ç–æ (–∞ —ó—Ö –º–∞–π–∂–µ –∑–∞–≤–∂–¥–∏ –Ω–µ–±–∞–≥–∞—Ç–æ)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --ignore-installed http://nlp.band/static/pypy/lpnlp-2023.10.2-py3-none-any.whl"
      ],
      "metadata": {
        "id": "zBBM2S6_jI8r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3BcrrZzDGZ6",
        "outputId": "a0204d82-c540-4b19-b66b-cec24722a831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import lpnlp\n",
        "lab = lpnlp.start(\n",
        "    email=\"vasyl.rusyn.kn.2021@lpnu.ua\",  # <---------------------- –ó–∞–ø–æ–≤–Ω—ñ—Ç—å —Ü–µ –ø–æ–ª–µ\n",
        "    lab=\"using_word_embeddings\",\n",
        "    )\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–£–¥–∞—á—ñ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdb5yxDGp_ig"
      },
      "source": [
        "# GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZQ5JifvDp_ig",
        "outputId": "435f4b69-dc5a-4502-8a36-52bb238f97e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KESE75BDp_ih"
      },
      "source": [
        "–ü–æ–≤–Ω–∏–π GloVe –º—ñ—Å—Ç–∏—Ç—å 4,000,000 –≤–µ–∫—Ç–æ—Ä—ñ–≤ —ñ –∑–∞–π–º–∞—î –±–∞–≥–∞—Ç–æ –ø–∞–º'—è—Ç—ñ. –©–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º –∑ –ø–∞–º'—è—Ç—é, –∑–∞–ª–∏—à–∏–º–æ –ª–∏—à–µ 50,000 –≤–µ–∫—Ç–æ—Ä—ñ–≤ –Ω–∞–π—á–∞—Å—Ç–æ—Ç–Ω—ñ—à–∏—Ö —Å–ª—ñ–≤. –¶–µ —Ç—Ä–æ—Ö–∏ –∑–Ω–∏–∑–∏—Ç—å —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π, –∞–ª–µ —Ü–µ –∑–∞—Ä–∞–∑ –Ω–µ –≥–æ–ª–æ–≤–Ω–µ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSPkhqoep_ih"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "glove = KeyedVectors.load(\"http://nlp.band/static/files/glove-50k.bin\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC899YNmp_ir"
      },
      "source": [
        "# Bag-of-embeddings\n",
        "\n",
        "–í–µ–∫—Ç–æ—Ä–∏ —Å–ª—ñ–≤, –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω—ñ –Ω–∞ –≤–µ–ª–∏–∫–æ–º—É –∫–æ—Ä–ø—É—Å—ñ —Ç–µ–∫—Å—Ç—ñ–≤, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è —Å–ª—ñ–≤ –∑–∞–º—ñ—Å—Ç—å —Ä–æ–∑—Ä—ñ–¥–∂–µ–Ω–∏—Ö one-hot, —è–∫—ñ –º–∏ –±–∞—á–∏–ª–∏ –≤ –ø–µ—Ä—à—ñ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ñ–π. Word embeddings —á—É–¥–æ–≤–æ –ø—Ä–∞—Ü—é—é—Ç—å –∑ –Ω–µ–π—Ä–æ–Ω–Ω–∏–º –º–µ—Ä–µ–∂–∞–º–∏ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω–∏—Ö –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä. –ê–ª–µ –∑–∞—Ä–∞–∑ –º–∏ —Ä–æ–∑–≥–ª—è–Ω–µ–º–æ –Ω–∞–ø—Ä–æ—Å—Ç—ñ—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è: –ª–æ–≥—ñ—Å—Ç–∏—á–Ω—É —Ä–µ–≥—Ä–µ—Å—ñ—é (—Ç–∞–∫, –∑–Ω–æ–≤—É) —Ç–∞ –º—ñ—à–æ–∫ –≤–µ–∫—Ç–æ—Ä—ñ–≤ (bag-of-embeddings).\n",
        "\n",
        "–í bag-of-embeddings –º–∏ —É—Å–µ—Ä–µ–¥–Ω—é—î–º–æ –≤–µ–∫—Ç–æ—Ä–∏ –≤—Å—ñ—Ö —Å–ª—ñ–≤, —è–∫—ñ –≤—Ö–æ–¥—è—Ç—å –≤ —Ä–µ—á–µ–Ω–Ω—è. –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –≤–µ–∫—Ç–æ—Ä —Ç–∞–∫–æ—ó –∂ —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ, —è–∫ —ñ –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞. –¶–µ–π –≤–µ–∫—Ç–æ—Ä –∫–æ–¥—É—î –∑–º—ñ—Å—Ç —É—Å—å–æ–≥–æ —Ä–µ—á–µ–Ω–Ω—è. –ó–≤–∏—á–∞–π–Ω–æ, —Ç–∞–∫–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –Ω–µ –≤—Ä–∞—Ö–æ–≤—É—î –ø–æ—Ä—è–¥–æ–∫ —Å–ª—ñ–≤, —Ä—ñ–≤–Ω–æ—Ü—ñ–Ω–Ω–æ —Å—Ç–∞–≤–∏—Ç—å—Å—è –¥–æ –≤–∞–∂–ª–∏–≤–∏—Ö —Ç–∞ –¥–æ–ø–æ–º—ñ–∂–Ω–∏—Ö —Å–ª—ñ–≤, –∞ —Ç–æ–º—É \"–∫–æ–¥—É—î\" –≤–æ–Ω–æ –∑–º—ñ—Å—Ç —Ä–µ—á–µ–Ω–Ω—è –≤–µ–ª—å–º–∏ –ø—Ä–∏–±–ª–∏–∑–Ω–æ. –ü—Ä–æ—Ç–µ —Ü—å–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è –±–∞–≥–∞—Ç—å–æ—Ö –ø—Ä–æ—Å—Ç–∏—Ö –∑–∞–¥–∞—á."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnj-EyYPp_ir"
      },
      "source": [
        "## –¢–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è\n",
        "\n",
        "–î–ª—è –ø–æ—á–∞—Ç–∫—É –Ω–∞–º —Ç—Ä–µ–±–∞ —Ç–æ–∫–µ–Ω—ñ–∑—É–≤–∞—Ç–∏ –∫–æ—Ä–ø—É—Å. –í–∞–∂–ª–∏–≤–∏–π –º–æ–º–µ–Ω—Ç: GloVe —Ç–∞ —ñ–Ω—à—ñ word embeddings —Ç—Ä–µ–Ω—É–≤–∞–ª–∏—Å—è –∫–æ–∂–µ–Ω –∑—ñ —Å–≤–æ—ó–º —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ç–æ—Ä–æ–º. –ù–∞–º —Å–ª—ñ–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å—Ö–æ–∂–∏–π —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ç–æ—Ä. –Ü–Ω–∞–∫—à–µ –º–∏ –Ω–µ –∑–º–æ–∂–µ–º–æ –∑–Ω–∞–π—Ç–∏ –≤–µ–∫—Ç–æ—Ä–∏ –¥–ª—è –±–∞–≥–∞—Ç—å–æ—Ö —Å–ª—ñ–≤.\n",
        "\n",
        "–ù–∞—Å–∞–º–ø–µ—Ä–µ–¥, GloVe —Ç—Ä–µ–Ω—É–≤–∞–ª–∏—Å—è –Ω–∞ —Ç–µ–∫—Å—Ç—ñ, –ø—Ä–∏–≤–µ–¥–µ–Ω–æ–º—É –¥–æ –Ω–∏–∂–Ω—å–æ–≥–æ —Ä–µ–≥—ñ—Å—Ç—Ä—É. –¢–∞–∫–æ–∂ —Ä–æ–∑–±—ñ–∂–Ω–æ—Å—Ç—ñ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –≤ –∫–æ–¥—É–≤–∞–Ω–Ω—ñ —Å–ª—ñ–≤ —Ç–∏–ø—É `I'll` (—Ç–æ–∫–µ–Ω—ñ–∑—É—î—Ç—å—Å—è –≤ –¥–≤–∞ —Ç–æ–∫–µ–Ω–∏ `I 'll` —á–∏ –≤ –æ–¥–∏–Ω —Ç–æ–∫–µ–Ω `I'll`?), `don't`, `I've` —ñ –ø–æ–¥—ñ–±–Ω–∏—Ö.\n",
        "\n",
        "–ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ, —è–∫–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—ó –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î GloVe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwSeYexXp_is",
        "outputId": "9e7ba8c4-6df7-4a83-c3c6-4e7c7127fc24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"don't\" in glove"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7PLcDlop_is",
        "outputId": "0e9f54a7-8211-454a-cbf8-da029e1eea54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"n't\" in glove"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InXjt_Oap_is",
        "outputId": "f2845c25-a040-432b-c8d7-ee4adc31c0ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"I'll\" in glove"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIGf6CMdp_it",
        "outputId": "e047118f-f07b-4bd7-8061-73ef52cd9476",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"'ll\" in glove"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"<unk>\" in glove"
      ],
      "metadata": {
        "id": "GefjPZnH4qPU",
        "outputId": "928ab6c6-14aa-45ce-f7a1-308dbca30abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Zyzasep_it"
      },
      "source": [
        "–û—Ç–∂–µ, –º–∞—î–º–æ —Ä–æ–∑–±–∏–≤–∞—Ç–∏ `don't` –Ω–∞ –¥–≤–∞ —Ç–æ–∫–µ–Ω–∏: `do` + `n't`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8pkOJMrp_it",
        "outputId": "8d430ea8-252a-437f-9b0b-dea0011e0c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "from typing import List\n",
        "\n",
        "\n",
        "spacy_nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "  \"\"\"Tokenize string with SpaCy. \"\"\"\n",
        "\n",
        "  tokens = spacy_nlp.tokenizer(text)\n",
        "  return [str(token).lower() for token in tokens]\n",
        "\n",
        "tokenize(\"I don't know\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'do', \"n't\", 'know']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDcdMxXLp_iu"
      },
      "source": [
        "## –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
        "\n",
        "–¢–µ–ø–µ—Ä –º–æ–∂–µ–º–æ –ø–æ—Ä–∞—Ö—É–≤–∞—Ç–∏ –≤–µ–∫—Ç–æ—Ä –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç—É –≤ –∫–æ—Ä–ø—É—Å. –¶–µ–π –≤–µ–∫—Ç–æ—Ä –±—É–¥–µ –¥–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏ —Å–µ—Ä–µ–¥–Ω—å–æ–º—É –≤—ñ–¥ –≤–µ–∫—Ç–æ—Ä—ñ–≤ –æ–∫—Ä–µ–º–∏—Ö —Å–ª—ñ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLbkwgWdp_iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3657783e-9ce9-443b-88e2-73c351912b01"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "def bag_of_embeddings(doc: str, embeddings: KeyedVectors) -> np.ndarray:\n",
        "    tokens = tokenize(doc)\n",
        "    not_present_tokens_count = 0\n",
        "    ##################################################\n",
        "    doc_vector = np.zeros(len(embeddings[\"'ll\"]))                 # <------------------- –≤–∞—à –∫–æ–¥\n",
        "    for token in tokens:\n",
        "      # KeyError: \"Key 'cccc' not present\" - this makes me skip all not present tokens, Also I am surprised that <unk> is not in glove\n",
        "      if token in glove:\n",
        "        #print(token)\n",
        "        doc_vector += embeddings[token]\n",
        "      else:\n",
        "        not_present_tokens_count += 1\n",
        "    doc_vector /= (len(tokens) - not_present_tokens_count)\n",
        "    ##################################################\n",
        "\n",
        "    return doc_vector\n",
        "\n",
        "\n",
        "doc_embedding = bag_of_embeddings(\"Hello world!\", glove)\n",
        "print(f\"Embedding: {doc_embedding}\")\n",
        "print(f\"Shape:     {doc_embedding.shape}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding: [ 0.41083999  0.49570001 -0.35982667 -0.40393333 -0.19768667  0.25433\n",
            " -0.5149      0.086394    0.04418867  0.36530902 -0.35623667  0.15675334\n",
            "  0.0924      0.4017      0.00335333 -0.08881667 -0.37311666  0.57041667\n",
            "  0.04311933  0.34267666  0.47882667  1.48930599  0.25857667 -0.19864706\n",
            "  0.10432334  0.125766    0.10343501 -0.28578333 -0.31660533  0.013828\n",
            " -0.07466667  0.13855    -0.32214699 -0.28048033 -0.41403     0.06308667\n",
            " -0.23955599 -0.03680334 -0.141137   -0.0916     -0.16916067  0.57163533\n",
            " -0.31253667  0.07347333 -0.16953167  0.20232     0.60658666  0.06445\n",
            " -0.01957     0.30073999  0.21663668 -0.06867134  0.40304667  0.07233367\n",
            " -0.17247333  0.20601167 -0.39143999 -0.02245933 -0.17295867 -0.19998033\n",
            "  0.234197   -0.29320667 -0.13344    -0.1644     -0.00662334  0.01097\n",
            " -0.00953534  0.50209667  0.42084     0.03766001  0.46454333 -0.44661133\n",
            "  0.22226367  0.0327     -0.43125998  0.00774    -0.15634833  0.38859933\n",
            " -0.38001334 -0.13208101  0.22859666 -0.39621334  0.24020334  0.41949667\n",
            " -0.64736667 -0.11796334  0.300212   -0.04890667  0.19057    -0.65398\n",
            " -0.09819667  0.09049634 -0.12865367 -0.19084066 -0.30180568  0.07661999\n",
            "  0.03418794 -0.029667   -0.14523334 -0.23192567  0.09882666  0.43341334\n",
            "  0.047808   -0.09808999  0.26746066 -0.23435799  0.12239434  0.81658\n",
            " -0.44904668  0.55188332 -0.29156666 -0.33961267  0.30957001  0.06785334\n",
            " -0.43108668  0.30085501  0.265036    0.64703665 -0.71364333  0.01400334\n",
            "  0.10547134 -0.07894     0.25629333 -0.21767333  0.250195   -0.59736667\n",
            "  0.28668667 -0.05228666  0.23764335 -0.49035334 -0.45085333 -0.51667001\n",
            " -0.01609633 -0.32716001 -0.22492333 -0.47330332 -0.15200033  0.20181667\n",
            " -0.24229133  0.189256   -0.060564   -0.219731    0.24458    -0.28706333\n",
            "  0.66340666  0.27743334 -0.49113    -0.26614667 -0.22016666  0.50276666\n",
            "  0.48637666  0.28844333 -0.2935419   0.45673667  0.23382999  0.5161\n",
            " -0.19783267 -0.18264267  0.01969201 -0.013066    0.08293099  0.02575266\n",
            " -0.05760333 -0.30384001  0.28911    -0.30737334 -0.07102667 -0.11787967\n",
            " -0.35104669 -0.23236666  0.15019667 -0.01766733  0.61937333  0.16082666\n",
            " -0.11402834  0.14723667 -0.69580332 -0.23911467  0.234387    0.35806335\n",
            "  1.49516666 -0.21275433 -0.30564667  0.17912033 -0.31634    -0.69530334\n",
            "  0.20261667  0.47446965  0.2579     -0.62837998 -0.13436667 -0.18600167\n",
            " -0.14682833  0.03335    -0.06864333 -0.24147433 -0.15195    -0.13681023\n",
            " -0.05313335  0.34631001]\n",
            "Shape:     (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Å–ª—ñ–≤ —É –Ω—å–æ–º—É:"
      ],
      "metadata": {
        "id": "ef2tBQytUvkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"Hello world\",\n",
        "    \"You can try the best you can. The best you can is good enough.\",\n",
        "]\n",
        "print(\"–†–æ–∑–º—ñ—Ä    –î–æ–∫—É–º–µ–Ω—Ç\")\n",
        "print(\"-\" * 80)\n",
        "for s in tests:\n",
        "    shape = bag_of_embeddings(\"Hello world!\", glove).shape\n",
        "    print(f\"{shape}    {s}\")"
      ],
      "metadata": {
        "id": "DNvRbFEoUz4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7017a69c-08b9-46eb-ec41-3bb6f4978796"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–†–æ–∑–º—ñ—Ä    –î–æ–∫—É–º–µ–Ω—Ç\n",
            "--------------------------------------------------------------------------------\n",
            "(200,)    Hello world\n",
            "(200,)    You can try the best you can. The best you can is good enough.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.checkpoint(\"`Hello world` centroid\", bag_of_embeddings(\"Hello world!\", glove).mean())"
      ],
      "metadata": {
        "id": "xKrsXe7DVPR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdad603-4294-465e-a1ba-b00c2be0e058"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0046237471218531275"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRL0YDoop_iu"
      },
      "source": [
        "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –≤—Å—å–æ–≥–æ –∫–æ—Ä–ø—É—Å—É\n",
        "\n",
        "–ù–∞—Å—Ç—É–ø–Ω–∞ –æ–ø–µ—Ä–∞—Ü—ñ—è –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ –ø–∞—Ä—É —Ö–≤–∏–ª–∏–Ω:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3YZqlcOvkV3"
      },
      "source": [
        "!pip install --quiet datasets"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QWs_M95p_iu"
      },
      "source": [
        "import datasets\n",
        "imdb = datasets.load_dataset(\"imdb\")\n",
        "\n",
        "valid_data = imdb[\"test\"].shuffle(seed=1).filter(lambda x, i: i < 2000, with_indices=True)  # take 2000 random rows for validation\n",
        "train_data = imdb[\"train\"].shuffle(seed=2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def custom_vectorize_dataset(dataset: datasets.Dataset) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"–í–µ–∫—Ç–æ—Ä—ñ–∑—É—î –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç —É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è bag-of-embeddings.\n",
        "\n",
        "    –ü–æ–≤–µ—Ä—Ç–∞—î –º–∞—Ç—Ä–∏—Ü—é –æ–∑–Ω–∞–∫ X —Ç–∞ –≤–µ–∫—Ç–æ—Ä –∫–ª–∞—Å—ñ–≤ y.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    for doc in tqdm(dataset):\n",
        "        doc_vector = bag_of_embeddings(doc[\"text\"], glove)\n",
        "        X.append(doc_vector)\n",
        "\n",
        "    X = np.stack(X)\n",
        "    y = np.array(dataset[\"label\"])\n",
        "    return (X, y)"
      ],
      "metadata": {
        "id": "uMDsl8LPUfZ2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxA_y-PPp_iu",
        "outputId": "a2d53dda-b82f-442e-d4de-ca218f84610e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_boe, y_train_boe = custom_vectorize_dataset(train_data)\n",
        "X_valid_boe, y_valid_boe = custom_vectorize_dataset(valid_data)\n",
        "lab.checkpoint(\"Vectorized dataset shape\", X_train_boe.shape)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25000/25000 [01:25<00:00, 291.34it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:06<00:00, 288.29it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FK-cMukZZqUh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xORrcb8ap_iv"
      },
      "source": [
        "## Logistic regression + Bag-of-Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –®—Ç—É—á–Ω–æ –æ–±–º–µ–∂–∏–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ —Ü–∏–º –∑–Ω–∞—á–µ–Ω–Ω—è–º.\n",
        "# –¢–∞–∫ –º–∏ –µ–º—É–ª—é—î–º–æ —Å–∏—Ç—É–∞—Ü—ñ—é, –∫–æ–ª–∏ –≤ –Ω–∞—Å –º–∞–ª–æ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö.\n",
        "#TRAIN_SIZE = 25000"
      ],
      "metadata": {
        "id": "43OKsPYeWlw8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iftv_Jq9p_iv"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def embedding_model(TRAIN_SIZE):\n",
        "  # –¢—Ä–µ–Ω—É—î–º–æ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω—É —Ä–µ–≥—Ä–µ—Å—ñ—é\n",
        "  logreg = LogisticRegression(solver=\"liblinear\")\n",
        "\n",
        "  logreg.fit(X_train_boe[:TRAIN_SIZE,], y_train_boe[:TRAIN_SIZE,])\n",
        "  logreg_acc = logreg.score(X_valid_boe, y_valid_boe)\n",
        "  print(f\"LogReg + BoE accuracy on {TRAIN_SIZE}\", logreg_acc)\n",
        "  lab.checkpoint(f\"LogReg + BoE accuracy on {TRAIN_SIZE}\", logreg_acc)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression + TF-IDF\n",
        "\n",
        "–ù–∞—Ç—Ä–µ–Ω—É—î–º–æ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª—å –Ω–∞ TF-IDF bag-of-ngrams –æ–∑–Ω–∞–∫–∞—Ö. –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ —Ç–æ—á–Ω—ñ—Å—ñ–Ω—å–∫–æ —Ç–∞–∫—ñ, —è–∫ —ñ —É –º–æ–¥–µ–ª—ñ bag-of-embeddings. –ê–ª–µ —è–∫ —â–æ–¥–æ —è–∫–æ—Å—Ç—ñ?\n"
      ],
      "metadata": {
        "id": "vJBKiOWBfnr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_model(TRAIN_SIZE):\n",
        "  vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "  X_train_bow = vectorizer.fit_transform(train_data[:TRAIN_SIZE][\"text\"])\n",
        "\n",
        "  model_tfidf = LogisticRegression(solver='liblinear', C=0.2, penalty=\"l1\")\n",
        "  model_tfidf.fit(X_train_bow, train_data[\"label\"][:TRAIN_SIZE])\n",
        "\n",
        "\n",
        "  X_valid_bow = vectorizer.transform(valid_data[\"text\"])\n",
        "  y_valid_bow = valid_data[\"label\"]\n",
        "  tfidf_acc = model_tfidf.score(X_valid_bow, y_valid_bow)\n",
        "  print(f\"LogReg + TF-IDF accuracy on {TRAIN_SIZE}\", tfidf_acc)\n",
        "  lab.checkpoint(f\"LogReg + TF-IDF accuracy on {TRAIN_SIZE}\", tfidf_acc)"
      ],
      "metadata": {
        "id": "K-I-Ij3_Gzbw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [500, 1000, 2500, 5000, 10000, 25000]:\n",
        "  embedding_model(i)\n",
        "  tfidf_model(i)"
      ],
      "metadata": {
        "id": "bXssNs8W-npU",
        "outputId": "b88e6c71-2140-4b23-835a-92dfad067e62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogReg + BoE accuracy on 500 0.7325\n",
            "LogReg + TF-IDF accuracy on 500 0.5035\n",
            "LogReg + BoE accuracy on 1000 0.773\n",
            "LogReg + TF-IDF accuracy on 1000 0.5035\n",
            "LogReg + BoE accuracy on 2500 0.7935\n",
            "LogReg + TF-IDF accuracy on 2500 0.656\n",
            "LogReg + BoE accuracy on 5000 0.803\n",
            "LogReg + TF-IDF accuracy on 5000 0.7415\n",
            "LogReg + BoE accuracy on 10000 0.805\n",
            "LogReg + TF-IDF accuracy on 10000 0.8\n",
            "LogReg + BoE accuracy on 25000 0.8135\n",
            "LogReg + TF-IDF accuracy on 25000 0.8365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ó–∞–≤–¥–∞–Ω–Ω—è\n",
        "\n",
        "–ü–µ—Ä–µ—Ç—Ä–µ–Ω—É–π—Ç–µ –º–æ–¥–µ–ª—ñ –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä–∞—Ö `TRAIN_SIZE`. –°–ø—Ä–æ–±—É–π—Ç–µ –∫—ñ–ª—å–∫–∞ –∑–Ω–∞—á–µ–Ω—å. –ó–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É, —è–∫ —Ä—ñ–∑–Ω–∏—Ü—é –º—ñ–∂ –º–æ–¥–µ–ª—è–º–∏ –∑–º—ñ–Ω—é—î—Ç—å—Å—è –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ `TRAIN_SIZE`.\n",
        "\n",
        "‚ùó –†–µ–∑—É–ª—å—Ç–∞—Ç (–ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –≤–∞—à Google Colab –∞–±–æ PDF) –≤—ñ–¥–ø—Ä–∞–≤—Ç–µ –Ω–∞ –ø–æ—à—Ç—É oleksii.o.syvokon@lpnu.ua ‚ùó"
      ],
      "metadata": {
        "id": "UhrxAf4IgT5G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVoUZm0lxGds"
      },
      "source": [
        "# Embeddings matrix\n",
        "\n",
        "–î–æ—Å—ñ –¥–ª—è –¥–æ—Å—Ç—É–ø—É –¥–æ –≤–µ–∫—Ç–æ—Ä—ñ–≤ —Å–ª—ñ–≤ –º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞–ª–∏—Å—è –±—ñ–±–ª—ñ–æ—Ç–µ–∫–æ—é `gensim`, —è–∫–∞ –Ω–∞–¥–∞–≤–∞–ª–∞ –Ω–∞–º —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–ª–æ–≤–Ω–∏–∫–∞ (`dict`).\n",
        "\n",
        "–ü—ñ–¥ –∫–∞–ø–æ—Ç–æ–º, –≤–µ–∫—Ç–æ—Ä–∏ —Å–ª—ñ–≤ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ –æ–¥–Ω—ñ–π –º–∞—Ç—Ä–∏—Ü—ñ —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ $|V| \\times d$, –¥–µ $|V|$ —Ü–µ —Ä–æ–∑–º—ñ—Ä —Å–ª–æ–≤–Ω–∏–∫–∞ (—Å–∫—ñ–ª—å–∫–∏ —Å–ª—ñ–≤ –º–∞—î–º–æ), –∞ $d$ ‚Äî —Ä–æ–∑–º—ñ—Ä –≤–µ–∫—Ç–æ—Ä–∞ —Å–ª–æ–≤–∞ (–≤ —Ü—ñ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ñ–π –±—É–ª–æ $d=200$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0a3Cxl9iDBn",
        "outputId": "f0fd3e79-6f64-47eb-9b06-666f0a6a84a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "glove.vectors.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VybrpjjOkrrR"
      },
      "source": [
        "–í –º–æ–¥–µ–ª—è—Ö –≥–ª–∏–±–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è, —è–∫ –ø—Ä–∞–≤–∏–ª–æ, —Å–ø—Ä–∞–≤—É –º–∞—é—Ç—å —Å–∞–º–µ –∑ —Ü—ñ—î—é embeddings matrix.\n",
        "\n",
        "–†–æ–∑–≥–ª—è–Ω–µ–º–æ –¥–≤–∞ —Å–ø–æ—Å–æ–±–∏ –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤–µ–∫—Ç–æ—Ä –ø–æ—Ç—Ä—ñ–±–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –∑ —Ü—ñ—î—ó –º–∞—Ç—Ä–∏—Ü—ñ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZGXRCNrlBde"
      },
      "source": [
        "## Vector-matrix multiplication\n",
        "\n",
        "–ü–µ—Ä—à–∏–π —Å–ø–æ—Å—ñ–±, —Ü–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–∏ —Å–ª–æ–≤–æ –∑ —ñ–Ω–¥–µ–∫—Å–æ–º $i$ —É –≤–∏–≥–ª—è–¥—ñ one-hot –≤–µ–∫—Ç–æ—Ä–∞ $o_i$. –¢–æ–¥—ñ –µ–º–±–µ–¥—ñ–Ω–≥ –ø–æ—Ç—Ä—ñ–±–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –º–æ–∂–Ω–∞ –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ –¥–æ–±—É—Ç–∫—É\n",
        "\n",
        "$$e_i = \\text{E}^\\intercal o_i $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryDrswVlkoUk"
      },
      "source": [
        "import torch\n",
        "\n",
        "embeddings_matrix = torch.tensor(glove.vectors)\n",
        "\n",
        "def embed(token_index: int, embeddings_matrix: torch.tensor) -> torch.tensor:\n",
        "    vocab_size, embed_dim = embeddings_matrix.shape\n",
        "    one_hot = torch.zeros(vocab_size)\n",
        "    one_hot[token_index] = 1\n",
        "    return one_hot @ embeddings_matrix\n",
        "\n",
        "assert torch.allclose(\n",
        "    embed(42, embeddings_matrix),\n",
        "    torch.tensor(glove.vectors[42]))\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0xFJ6DUm6GW",
        "outputId": "e1602791-972b-4fd1-beac-f4bf13e1bfb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "lab.checkpoint(\"The embedding of one-hot multiplication\",\n",
        "               embed(42, embeddings_matrix).sum())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensor(5.3482)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4vqXSL4m2gF"
      },
      "source": [
        "## nn.Embedding\n",
        "\n",
        "–í PyTorch, —è–∫ —ñ –≤ –±—ñ–ª—å—à–æ—Å—Ç—ñ deep learning frameworks, —î —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è, —è–∫–∞ –ø–æ–≤–µ—Ä—Ç–∞—î –≤–µ–∫—Ç–æ—Ä –∑ –ø–æ—Ç—Ä—ñ–±–Ω–∏–º –Ω–æ–º–µ—Ä–æ–º: `torch.nn.Embedding`. –í–æ–Ω–∞ —ñ–º–ø–ª–µ–º–µ–Ω—Ç–æ–≤–∞–Ω–∞ –±—ñ–ª—å—à –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ, –Ω—ñ–∂ —Å–ø–æ—Å—ñ–± –∑ vector-matrix multiplication, —Ç–æ–∂ –≤ –±—ñ–ª—å—à–æ—Å—Ç—ñ –≤–∏–ø–∞–¥–∫—ñ–≤ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ç–∏—Å—è –≤–∞—Ä—Ç–æ —Å–∞–º–µ `nn.Embedding`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A29kVgWvrr9I"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "embeddings = nn.Embedding(num_embeddings=50_000, embedding_dim=200, _weight=embeddings_matrix)\n",
        "indexes = torch.LongTensor([42])\n",
        "embedded = embeddings(indexes)\n",
        "\n",
        "assert np.isclose(embedded.sum().item(), glove.vectors[42].sum())"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTBXxCdutJLG",
        "outputId": "640f9e8f-52bc-4680-b4a9-aa5115411f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lab.checkpoint(\"nn.Embeddings\", embedded.sum().item())"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.34816837310791"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ì–æ—Ç–æ–≤–æ!"
      ],
      "metadata": {
        "id": "7U97-goHHZrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lab.answer(\"ALL DONE! üòä\")"
      ],
      "metadata": {
        "id": "ZUariUJ2HiQ6",
        "outputId": "36192c77-8e2a-410d-f455-6aa186cb9d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–í—ñ–¥–ø–æ–≤—ñ–¥—å –ø—Ä–∞–≤–∏–ª—å–Ω–∞ ‚úÖ\n",
            "üí™\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ALL DONE! üòä'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}